# @package _global_
algorithm: SAC

algorithm_kwargs:
  # Hyperparameters
  n_policy_units: 8
  n_critic_units: 8
  soft_update_weight: 0.01

  replay_buffer_class:
    _target_: mighty.mighty_replay.MightyReplay  # Using replay buffer
  replay_buffer_kwargs:
     capacity: 1000000  # Maximum size of replay buffer.

  # Training
  learning_rate: 0.001
  batch_size: 256  # Batch size for training.
  gamma: 0.99  # The amount by which to discount future rewards.
  tau: 0.005  # Soft update parameter for target networks.
  alpha: 0.2  # Initial value for alpha if not using automatic tuning.

  policy_class: mighty.mighty_exploration.StochasticPolicy  # Policy class for exploration
  policy_kwargs:
    entropy_coefficient: 0.2  # Coefficient for entropy-based exploration.
    discrete: False  # Continuous action space.