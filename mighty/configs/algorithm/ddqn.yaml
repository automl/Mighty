# @package _global_
algorithm: DDQN
q_func: ???

algorithm_kwargs:
  # Hyperparameters
  discount_factor: 0.9
  epsilon: 0.2  # Controls epsilon-greedy action selection in policy.

  replay_buffer_class:
    _target_: coax.experience_replay.SimpleReplayBuffer
  replay_buffer_kwargs:
    capacity: 1000000  # Maximum size of replay buffer.
    random_seed: ${seed}

  # Training
  learning_rate: 0.001
  batch_size: 64  # Batch size for training.
  n_step_reward_tracing: 1  # The number of steps over which to bootstrap.
#  begin_updating_weights: 1  # Begin updating policy weights after this many observed transitions.
#  soft_update_weight: 0.01  #